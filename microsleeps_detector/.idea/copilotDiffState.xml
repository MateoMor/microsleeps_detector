<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/app/src/main/AndroidManifest.xml">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/app/src/main/AndroidManifest.xml" />
              <option name="originalContent" value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&#10;&lt;manifest xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot;&#10;    xmlns:tools=&quot;http://schemas.android.com/tools&quot;&gt;&#10;    &lt;uses-permission android:name=&quot;android.permission.CAMERA&quot;/&gt;&#10;    &lt;uses-permission android:name=&quot;android.permission.INTERNET&quot;/&gt;&#10;    &lt;uses-feature android:name=&quot;android.hardware.camera.any&quot;/&gt;&#10;&#10;    &lt;application&#10;        android:allowBackup=&quot;true&quot;&#10;        android:dataExtractionRules=&quot;@xml/data_extraction_rules&quot;&#10;        android:fullBackupContent=&quot;@xml/backup_rules&quot;&#10;        android:icon=&quot;@mipmap/ic_launcher&quot;&#10;        android:label=&quot;@string/app_name&quot;&#10;        android:roundIcon=&quot;@mipmap/ic_launcher_round&quot;&#10;        android:supportsRtl=&quot;true&quot;&#10;        android:theme=&quot;@style/Theme.Microsleeps_detector&quot;&#10;        android:usesCleartextTraffic=&quot;true&quot;&gt;&#10;        &lt;activity&#10;            android:name=&quot;.MainActivity&quot;&#10;            android:exported=&quot;true&quot;&#10;            android:theme=&quot;@style/Theme.Microsleeps_detector&quot;&gt;&#10;            &lt;intent-filter&gt;&#10;                &lt;action android:name=&quot;android.intent.action.MAIN&quot; /&gt;&#10;&#10;                &lt;category android:name=&quot;android.intent.category.LAUNCHER&quot; /&gt;&#10;            &lt;/intent-filter&gt;&#10;        &lt;/activity&gt;&#10;&#10;    &lt;/application&gt;&#10;&#10;&lt;/manifest&gt;" />
              <option name="updatedContent" value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&#10;&lt;manifest xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot;&#10;    xmlns:tools=&quot;http://schemas.android.com/tools&quot;&gt;&#10;    &lt;uses-permission android:name=&quot;android.permission.CAMERA&quot;/&gt;&#10;    &lt;uses-permission android:name=&quot;android.permission.INTERNET&quot;/&gt;&#10;    &lt;uses-permission android:name=&quot;android.permission.VIBRATE&quot;/&gt;&#10;    &lt;uses-feature android:name=&quot;android.hardware.camera.any&quot;/&gt;&#10;&#10;    &lt;application&#10;        android:allowBackup=&quot;true&quot;&#10;        android:dataExtractionRules=&quot;@xml/data_extraction_rules&quot;&#10;        android:fullBackupContent=&quot;@xml/backup_rules&quot;&#10;        android:icon=&quot;@mipmap/ic_launcher&quot;&#10;        android:label=&quot;@string/app_name&quot;&#10;        android:roundIcon=&quot;@mipmap/ic_launcher_round&quot;&#10;        android:supportsRtl=&quot;true&quot;&#10;        android:theme=&quot;@style/Theme.Microsleeps_detector&quot;&#10;        android:usesCleartextTraffic=&quot;true&quot;&gt;&#10;        &lt;activity&#10;            android:name=&quot;.MainActivity&quot;&#10;            android:exported=&quot;true&quot;&#10;            android:theme=&quot;@style/Theme.Microsleeps_detector&quot;&gt;&#10;            &lt;intent-filter&gt;&#10;                &lt;action android:name=&quot;android.intent.action.MAIN&quot; /&gt;&#10;&#10;                &lt;category android:name=&quot;android.intent.category.LAUNCHER&quot; /&gt;&#10;            &lt;/intent-filter&gt;&#10;        &lt;/activity&gt;&#10;&#10;    &lt;/application&gt;&#10;&#10;&lt;/manifest&gt;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/app/src/main/java/com/example/microsleeps_detector/StreamFragment.kt">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/app/src/main/java/com/example/microsleeps_detector/StreamFragment.kt" />
              <option name="originalContent" value="package com.example.microsleeps_detector&#10;&#10;import android.graphics.BitmapFactory&#10;import android.os.Bundle&#10;import android.view.LayoutInflater&#10;import android.view.View&#10;import android.view.ViewGroup&#10;import android.widget.Toast&#10;import androidx.fragment.app.Fragment&#10;import com.example.microsleeps_detector.databinding.FragmentStreamBinding&#10;import com.example.microsleeps_detector.ui.LabelsRenderer&#10;import kotlinx.coroutines.*&#10;import okhttp3.OkHttpClient&#10;import okhttp3.Request&#10;import java.io.IOException&#10;import android.util.Log&#10;import java.util.concurrent.TimeUnit&#10;&#10;private val TAG = &quot;StreamFragment&quot;&#10;&#10;class StreamFragment : Fragment(), FaceLandmarkerHelper.LandmarkerListener {&#10;&#10;    private var _binding: FragmentStreamBinding? = null&#10;    private val binding get() = _binding!!&#10;&#10;    // For visualization adjustments&#10;    private val imageRotation = 90f&#10;&#10;    private val streamUrl = &quot;http://192.168.43.74/stream&quot;&#10;    //private val streamUrl = &quot;http://10.253.50.3/stream&quot;&#10;    //private val streamUrl = &quot;http://192.168.4.1/stream&quot;&#10;    private val client = OkHttpClient.Builder()&#10;        .connectTimeout(10, TimeUnit.SECONDS)&#10;        .readTimeout(30, TimeUnit.SECONDS)&#10;        .build()&#10;    private var streamJob: Job? = null&#10;    private var renderer: LabelsRenderer? = null&#10;&#10;    override fun onCreateView(&#10;        inflater: LayoutInflater,&#10;        container: ViewGroup?,&#10;        savedInstanceState: Bundle?&#10;    ): View {&#10;        _binding = FragmentStreamBinding.inflate(inflater, container, false)&#10;        return binding.root&#10;    }&#10;&#10;    override fun onViewCreated(view: View, savedInstanceState: Bundle?) {&#10;        super.onViewCreated(view, savedInstanceState)&#10;        renderer = LabelsRenderer(binding)&#10;        Log.e(TAG, &quot;Starting StreamFragment&quot;)&#10;        startStream()&#10;    }&#10;&#10;    private fun startStream() {&#10;        Log.e(TAG, &quot;Starting stream&quot;)&#10;        streamJob = CoroutineScope(Dispatchers.IO).launch {&#10;            try {&#10;                Log.e(TAG, &quot;Trying to connect to stream: $streamUrl&quot;)&#10;                val request = Request.Builder().url(streamUrl).build()&#10;                val response = client.newCall(request).execute()&#10;&#10;                Log.d(TAG, &quot;Response code=${response.code}&quot;)&#10;&#10;                if (!response.isSuccessful) {&#10;                    Log.e(TAG, &quot;Response not successful: ${response.code}&quot;)&#10;                    withContext(Dispatchers.Main) {&#10;                        renderer?.setStatus(&quot;Error: ${response.code}&quot;)&#10;                    }&#10;                    return@launch&#10;                }&#10;&#10;                val inputStream = response.body?.byteStream()&#10;                if (inputStream != null) {&#10;                    Log.d(TAG, &quot;Connected, starting MJPEG parser&quot;)&#10;                    withContext(Dispatchers.Main) {&#10;                        renderer?.setStatus(&quot;Connected to stream&quot;)&#10;                    }&#10;                    parseMjpegStream(inputStream)&#10;                } else {&#10;                    Log.e(TAG, &quot;Response body is null&quot;)&#10;                    withContext(Dispatchers.Main) {&#10;                        renderer?.setStatus(&quot;Empty response body&quot;)&#10;                    }&#10;                }&#10;            } catch (e: Exception) {&#10;                Log.e(TAG, &quot;Exception in startStream: ${e.message}&quot;, e)&#10;                withContext(Dispatchers.Main) {&#10;                    renderer?.setStatus(&quot;Error: ${e.message}&quot;)&#10;                }&#10;            }&#10;        }&#10;    }&#10;&#10;    private suspend fun processFrameForFaceDetection(bitmap: android.graphics.Bitmap) {&#10;        withContext(Dispatchers.IO) {&#10;            try {&#10;                val helper = (requireActivity() as MainActivity).faceHelperOrNull()&#10;                if (helper == null) {&#10;                    Log.w(TAG, &quot;FaceLandmarkerHelper not available&quot;)&#10;                    return@withContext&#10;                }&#10;&#10;                // Convertir Bitmap a MPImage&#10;                val mpImage = com.google.mediapipe.framework.image.BitmapImageBuilder(bitmap).build()&#10;&#10;                // Detectar con timestamp actual&#10;                val timestamp = android.os.SystemClock.uptimeMillis()&#10;                helper.detectAsync(mpImage, timestamp)&#10;&#10;            } catch (e: Exception) {&#10;                Log.e(TAG, &quot;Error processing frame for face detection: ${e.message}&quot;, e)&#10;            }&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Rota un Bitmap por los grados especificados.&#10;     * @param source Bitmap original&#10;     * @param degrees Grados de rotación (0, 90, 180, 270)&#10;     * @return Bitmap rotado&#10;     */&#10;    private fun rotateBitmap(source: android.graphics.Bitmap, degrees: Float): android.graphics.Bitmap {&#10;        if (degrees == 0f) return source&#10;&#10;        val matrix = android.graphics.Matrix().apply {&#10;            postRotate(degrees)&#10;        }&#10;&#10;        return android.graphics.Bitmap.createBitmap(&#10;            source, 0, 0, source.width, source.height, matrix, true&#10;        )&#10;    }&#10;&#10;    private suspend fun parseMjpegStream(inputStream: java.io.InputStream) {&#10;        try {&#10;            val buffer = ByteArray(1024 * 64)&#10;            var bytesRead: Int&#10;            val frameBuffer = mutableListOf&lt;Byte&gt;()&#10;            var contentLength = 0&#10;            var isReadingHeader = true&#10;            var isReadingJpeg = false&#10;&#10;            while (streamJob?.isActive == true) {&#10;                bytesRead = withContext(Dispatchers.IO) {&#10;                    inputStream.read(buffer)&#10;                }&#10;&#10;                if (bytesRead &lt;= 0) {&#10;                    Log.d(TAG, &quot;Stream ended&quot;)&#10;                    break&#10;                }&#10;&#10;                for (i in 0 until bytesRead) {&#10;                    val byte = buffer[i]&#10;                    frameBuffer.add(byte)&#10;&#10;                    if (isReadingHeader) {&#10;                        // Convert buffer to string to search for Content-Length&#10;                        if (frameBuffer.size &gt; 50) {&#10;                            val frameStr = try {&#10;                                String(frameBuffer.toByteArray(), Charsets.UTF_8)&#10;                            } catch (e: Exception) {&#10;                                &quot;&quot;&#10;                            }&#10;&#10;                            val contentLengthMatch = Regex(&quot;Content-Length: (\\d+)&quot;).find(frameStr)&#10;                            if (contentLengthMatch != null) {&#10;                                contentLength = contentLengthMatch.groupValues[1].toInt()&#10;                                Log.d(TAG, &quot;Found Content-Length: $contentLength&quot;)&#10;                            }&#10;                        }&#10;&#10;                        // Detect end of headers (double CRLF: \r\n\r\n = 0x0D 0x0A 0x0D 0x0A)&#10;                        if (frameBuffer.size &gt;= 4 &amp;&amp;&#10;                            frameBuffer[frameBuffer.size - 4].toInt() and 0xFF == 0x0D &amp;&amp;&#10;                            frameBuffer[frameBuffer.size - 3].toInt() and 0xFF == 0x0A &amp;&amp;&#10;                            frameBuffer[frameBuffer.size - 2].toInt() and 0xFF == 0x0D &amp;&amp;&#10;                            frameBuffer[frameBuffer.size - 1].toInt() and 0xFF == 0x0A&#10;                        ) {&#10;                            isReadingHeader = false&#10;                            isReadingJpeg = true&#10;                            frameBuffer.clear()&#10;                            Log.d(TAG, &quot;Headers done, expecting $contentLength bytes of JPEG&quot;)&#10;                        }&#10;                    } else if (isReadingJpeg &amp;&amp; contentLength &gt; 0) {&#10;                        // We have enough bytes for a complete JPEG&#10;                        if (frameBuffer.size &gt;= contentLength) {&#10;                            Log.d(TAG, &quot;Got complete JPEG frame ($contentLength bytes)&quot;)&#10;                            val jpegData = frameBuffer.take(contentLength).toByteArray()&#10;                            val bitmap = BitmapFactory.decodeByteArray(jpegData, 0, jpegData.size)&#10;&#10;                            if (bitmap != null) {&#10;                                Log.d(TAG, &quot;Frame decoded (${bitmap.width}x${bitmap.height})&quot;)&#10;&#10;                                processFrameForFaceDetection(bitmap)&#10;&#10;                                val displayBitmap = rotateBitmap(bitmap, imageRotation)&#10;&#10;                                withContext(Dispatchers.Main) {&#10;                                    if (isAdded) {&#10;                                        binding.streamImageView.setImageBitmap(displayBitmap)&#10;                                    }&#10;                                }&#10;                                &#10;                                // Liberar bitmap rotado si es diferente del original&#10;                                if (displayBitmap != bitmap) {&#10;                                    displayBitmap.recycle()&#10;                                }&#10;                            } else {&#10;                                Log.w(TAG, &quot;Failed to decode bitmap&quot;)&#10;                            }&#10;&#10;                            frameBuffer.clear()&#10;                            isReadingHeader = true&#10;                            isReadingJpeg = false&#10;                            contentLength = 0&#10;                        }&#10;                    }&#10;                }&#10;            }&#10;        } catch (e: Exception) {&#10;            Log.e(TAG, &quot;Stream parser error: ${e.message}&quot;, e)&#10;            withContext(Dispatchers.Main) {&#10;                if (isAdded) {&#10;                    renderer?.setStatus(&quot;Stream error: ${e.message}&quot;)&#10;                }&#10;            }&#10;        }&#10;    }&#10;&#10;    override fun onResume() {&#10;        super.onResume()&#10;        (requireActivity() as MainActivity).setLandmarkerListener(this)&#10;    }&#10;&#10;    override fun onPause() {&#10;        super.onPause()&#10;        (requireActivity() as MainActivity).setLandmarkerListener(null)&#10;        streamJob?.cancel()&#10;    }&#10;&#10;    override fun onDestroyView() {&#10;        super.onDestroyView()&#10;        renderer = null&#10;        _binding = null&#10;        streamJob?.cancel()&#10;    }&#10;&#10;    // FaceLandmarkerHelper.LandmarkerListener&#10;&#10;    override fun onAnalysis(result: FaceAnalysis.Result) {&#10;        renderer?.render(result)&#10;    }&#10;&#10;    override fun onResults(resultBundle: FaceLandmarkerHelper.ResultBundle) {&#10;        if (!isAdded) return&#10;        requireActivity().runOnUiThread {&#10;            binding.overlay.setResults(resultBundle)&#10;        }&#10;    }&#10;&#10;    override fun onEmpty() {&#10;        if (!isAdded) return&#10;        renderer?.setStatus(&quot;No face detected&quot;)&#10;        requireActivity().runOnUiThread {&#10;            binding.overlay.clear()&#10;        }&#10;    }&#10;&#10;    override fun onError(error: String, errorCode: Int) {&#10;        if (!isAdded) return&#10;        renderer?.setStatus(&quot;Error: $error&quot;)&#10;        requireActivity().runOnUiThread {&#10;            Toast.makeText(requireContext(), error, Toast.LENGTH_SHORT).show()&#10;        }&#10;    }&#10;}" />
              <option name="updatedContent" value="package com.example.microsleeps_detector&#10;&#10;import android.graphics.BitmapFactory&#10;import android.os.Bundle&#10;import android.view.LayoutInflater&#10;import android.view.View&#10;import android.view.ViewGroup&#10;import android.widget.Toast&#10;import androidx.fragment.app.Fragment&#10;import com.example.microsleeps_detector.databinding.FragmentStreamBinding&#10;import com.example.microsleeps_detector.ui.LabelsRenderer&#10;import kotlinx.coroutines.*&#10;import okhttp3.OkHttpClient&#10;import okhttp3.Request&#10;import java.io.IOException&#10;import android.util.Log&#10;import java.util.concurrent.TimeUnit&#10;&#10;private val TAG = &quot;StreamFragment&quot;&#10;&#10;class StreamFragment : Fragment(), FaceLandmarkerHelper.LandmarkerListener {&#10;&#10;    private var _binding: FragmentStreamBinding? = null&#10;    private val binding get() = _binding!!&#10;&#10;    // For visualization adjustments&#10;    private val imageRotation = 90f&#10;&#10;    private val streamUrl = &quot;http://192.168.43.74/stream&quot;&#10;    //private val streamUrl = &quot;http://10.253.50.3/stream&quot;&#10;    //private val streamUrl = &quot;http://192.168.4.1/stream&quot;&#10;    private val client = OkHttpClient.Builder()&#10;        .connectTimeout(10, TimeUnit.SECONDS)&#10;        .readTimeout(30, TimeUnit.SECONDS)&#10;        .build()&#10;    private var streamJob: Job? = null&#10;    private var renderer: LabelsRenderer? = null&#10;&#10;    override fun onCreateView(&#10;        inflater: LayoutInflater,&#10;        container: ViewGroup?,&#10;        savedInstanceState: Bundle?&#10;    ): View {&#10;        _binding = FragmentStreamBinding.inflate(inflater, container, false)&#10;        return binding.root&#10;    }&#10;&#10;    override fun onViewCreated(view: View, savedInstanceState: Bundle?) {&#10;        super.onViewCreated(view, savedInstanceState)&#10;        renderer = LabelsRenderer(binding)&#10;        Log.e(TAG, &quot;Starting StreamFragment&quot;)&#10;        startStream()&#10;    }&#10;&#10;    private fun startStream() {&#10;        Log.e(TAG, &quot;Starting stream&quot;)&#10;        streamJob = CoroutineScope(Dispatchers.IO).launch {&#10;            try {&#10;                Log.e(TAG, &quot;Trying to connect to stream: $streamUrl&quot;)&#10;                val request = Request.Builder().url(streamUrl).build()&#10;                val response = client.newCall(request).execute()&#10;&#10;                Log.d(TAG, &quot;Response code=${response.code}&quot;)&#10;&#10;                if (!response.isSuccessful) {&#10;                    Log.e(TAG, &quot;Response not successful: ${response.code}&quot;)&#10;                    withContext(Dispatchers.Main) {&#10;                        renderer?.setStatus(&quot;Error: ${response.code}&quot;)&#10;                    }&#10;                    return@launch&#10;                }&#10;&#10;                val inputStream = response.body?.byteStream()&#10;                if (inputStream != null) {&#10;                    Log.d(TAG, &quot;Connected, starting MJPEG parser&quot;)&#10;                    withContext(Dispatchers.Main) {&#10;                        renderer?.setStatus(&quot;Connected to stream&quot;)&#10;                    }&#10;                    parseMjpegStream(inputStream)&#10;                } else {&#10;                    Log.e(TAG, &quot;Response body is null&quot;)&#10;                    withContext(Dispatchers.Main) {&#10;                        renderer?.setStatus(&quot;Empty response body&quot;)&#10;                    }&#10;                }&#10;            } catch (e: Exception) {&#10;                Log.e(TAG, &quot;Exception in startStream: ${e.message}&quot;, e)&#10;                withContext(Dispatchers.Main) {&#10;                    renderer?.setStatus(&quot;Error: ${e.message}&quot;)&#10;                }&#10;            }&#10;        }&#10;    }&#10;&#10;    private suspend fun processFrameForFaceDetection(bitmap: android.graphics.Bitmap) {&#10;        withContext(Dispatchers.IO) {&#10;            try {&#10;                val helper = (requireActivity() as MainActivity).faceHelperOrNull()&#10;                if (helper == null) {&#10;                    Log.w(TAG, &quot;FaceLandmarkerHelper not available&quot;)&#10;                    return@withContext&#10;                }&#10;&#10;                // Convertir Bitmap a MPImage&#10;                val mpImage = com.google.mediapipe.framework.image.BitmapImageBuilder(bitmap).build()&#10;&#10;                // Detectar con timestamp actual&#10;                val timestamp = android.os.SystemClock.uptimeMillis()&#10;                helper.detectAsync(mpImage, timestamp)&#10;&#10;            } catch (e: Exception) {&#10;                Log.e(TAG, &quot;Error processing frame for face detection: ${e.message}&quot;, e)&#10;            }&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Rota un Bitmap por los grados especificados.&#10;     * @param source Bitmap original&#10;     * @param degrees Grados de rotación (0, 90, 180, 270)&#10;     * @return Bitmap rotado&#10;     */&#10;    private fun rotateBitmap(source: android.graphics.Bitmap, degrees: Float): android.graphics.Bitmap {&#10;        if (degrees == 0f) return source&#10;&#10;        val matrix = android.graphics.Matrix().apply {&#10;            postRotate(degrees)&#10;        }&#10;&#10;        return android.graphics.Bitmap.createBitmap(&#10;            source, 0, 0, source.width, source.height, matrix, true&#10;        )&#10;    }&#10;&#10;    private suspend fun parseMjpegStream(inputStream: java.io.InputStream) {&#10;        try {&#10;            val buffer = ByteArray(1024 * 64)&#10;            var bytesRead: Int&#10;            val frameBuffer = mutableListOf&lt;Byte&gt;()&#10;            var contentLength = 0&#10;            var isReadingHeader = true&#10;            var isReadingJpeg = false&#10;&#10;            while (streamJob?.isActive == true) {&#10;                bytesRead = withContext(Dispatchers.IO) {&#10;                    inputStream.read(buffer)&#10;                }&#10;&#10;                if (bytesRead &lt;= 0) {&#10;                    Log.d(TAG, &quot;Stream ended&quot;)&#10;                    break&#10;                }&#10;&#10;                for (i in 0 until bytesRead) {&#10;                    val byte = buffer[i]&#10;                    frameBuffer.add(byte)&#10;&#10;                    if (isReadingHeader) {&#10;                        // Convert buffer to string to search for Content-Length&#10;                        if (frameBuffer.size &gt; 50) {&#10;                            val frameStr = try {&#10;                                String(frameBuffer.toByteArray(), Charsets.UTF_8)&#10;                            } catch (e: Exception) {&#10;                                &quot;&quot;&#10;                            }&#10;&#10;                            val contentLengthMatch = Regex(&quot;Content-Length: (\\d+)&quot;).find(frameStr)&#10;                            if (contentLengthMatch != null) {&#10;                                contentLength = contentLengthMatch.groupValues[1].toInt()&#10;                                Log.d(TAG, &quot;Found Content-Length: $contentLength&quot;)&#10;                            }&#10;                        }&#10;&#10;                        // Detect end of headers (double CRLF: \r\n\r\n = 0x0D 0x0A 0x0D 0x0A)&#10;                        if (frameBuffer.size &gt;= 4 &amp;&amp;&#10;                            frameBuffer[frameBuffer.size - 4].toInt() and 0xFF == 0x0D &amp;&amp;&#10;                            frameBuffer[frameBuffer.size - 3].toInt() and 0xFF == 0x0A &amp;&amp;&#10;                            frameBuffer[frameBuffer.size - 2].toInt() and 0xFF == 0x0D &amp;&amp;&#10;                            frameBuffer[frameBuffer.size - 1].toInt() and 0xFF == 0x0A&#10;                        ) {&#10;                            isReadingHeader = false&#10;                            isReadingJpeg = true&#10;                            frameBuffer.clear()&#10;                            Log.d(TAG, &quot;Headers done, expecting $contentLength bytes of JPEG&quot;)&#10;                        }&#10;                    } else if (isReadingJpeg &amp;&amp; contentLength &gt; 0) {&#10;                        // We have enough bytes for a complete JPEG&#10;                        if (frameBuffer.size &gt;= contentLength) {&#10;                            Log.d(TAG, &quot;Got complete JPEG frame ($contentLength bytes)&quot;)&#10;                            val jpegData = frameBuffer.take(contentLength).toByteArray()&#10;                            val bitmap = BitmapFactory.decodeByteArray(jpegData, 0, jpegData.size)&#10;&#10;                            if (bitmap != null) {&#10;                                Log.d(TAG, &quot;Frame decoded (${bitmap.width}x${bitmap.height})&quot;)&#10;&#10;                                processFrameForFaceDetection(bitmap)&#10;&#10;                                val displayBitmap = rotateBitmap(bitmap, imageRotation)&#10;&#10;                                withContext(Dispatchers.Main) {&#10;                                    if (isAdded) {&#10;                                        binding.streamImageView.setImageBitmap(displayBitmap)&#10;                                    }&#10;                                }&#10;                                &#10;                                // Liberar bitmap rotado si es diferente del original&#10;                                if (displayBitmap != bitmap) {&#10;                                    displayBitmap.recycle()&#10;                                }&#10;                            } else {&#10;                                Log.w(TAG, &quot;Failed to decode bitmap&quot;)&#10;                            }&#10;&#10;                            frameBuffer.clear()&#10;                            isReadingHeader = true&#10;                            isReadingJpeg = false&#10;                            contentLength = 0&#10;                        }&#10;                    }&#10;                }&#10;            }&#10;        } catch (e: Exception) {&#10;            Log.e(TAG, &quot;Stream parser error: ${e.message}&quot;, e)&#10;            withContext(Dispatchers.Main) {&#10;                if (isAdded) {&#10;                    renderer?.setStatus(&quot;Stream error: ${e.message}&quot;)&#10;                }&#10;            }&#10;        }&#10;    }&#10;&#10;    override fun onResume() {&#10;        super.onResume()&#10;        (requireActivity() as MainActivity).setLandmarkerListener(this)&#10;    }&#10;&#10;    override fun onPause() {&#10;        super.onPause()&#10;        (requireActivity() as MainActivity).setLandmarkerListener(null)&#10;        streamJob?.cancel()&#10;    }&#10;&#10;    override fun onDestroyView() {&#10;        super.onDestroyView()&#10;        renderer = null&#10;        _binding = null&#10;        streamJob?.cancel()&#10;    }&#10;&#10;    // FaceLandmarkerHelper.LandmarkerListener&#10;&#10;    override fun onAnalysis(result: FaceAnalysis.Result) {&#10;        renderer?.render(result)&#10;    }&#10;&#10;    override fun onResults(resultBundle: FaceLandmarkerHelper.ResultBundle) {&#10;        if (!isAdded) return&#10;        requireActivity().runOnUiThread {&#10;            binding.overlay.setResults(resultBundle)&#10;        }&#10;    }&#10;&#10;    override fun onEmpty() {&#10;        if (!isAdded) return&#10;        renderer?.setStatus(&quot;No face detected&quot;)&#10;        requireActivity().runOnUiThread {&#10;            binding.overlay.clear()&#10;        }&#10;    }&#10;&#10;    override fun onError(error: String, errorCode: Int) {&#10;        if (!isAdded) return&#10;        renderer?.setStatus(&quot;Error: $error&quot;)&#10;        requireActivity().runOnUiThread {&#10;            Toast.makeText(requireContext(), error, Toast.LENGTH_SHORT).show()&#10;        }&#10;    }&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>